# Flume配置文件 - 双通道配置
# Agent1: 离线分析通道 (logs目录 -> HDFS)
# Agent2: 实时分析通道 (generated_logs.json -> Kafka)

# ====================================================================
# Agent1: 离线分析通道 - spooldir source监听logs目录，输出到HDFS
# ====================================================================
agent1.sources = source_spooldir
agent1.sinks = sink_hdfs
agent1.channels = channel_offline

# --- Source: spooldir监听logs目录（单条文件形式） ---
agent1.sources.source_spooldir.type = spooldir
agent1.sources.source_spooldir.spoolDir = bigdata-engine/logs
agent1.sources.source_spooldir.fileHeader = true
agent1.sources.source_spooldir.consumeOrder = oldest
# 处理完成后添加.completed后缀
agent1.sources.source_spooldir.completedSuffix = .completed
# 忽略临时文件
agent1.sources.source_spooldir.ignorePattern = ^.*\\.tmp$

# --- Channel: 离线分析通道（文件类型，更可靠） ---
agent1.channels.channel_offline.type = file
agent1.channels.channel_offline.checkpointDir = ./flume/checkpoint_offline
agent1.channels.channel_offline.dataDirs = ./flume/data_offline
agent1.channels.channel_offline.capacity = 100000
agent1.channels.channel_offline.transactionCapacity = 10000

# --- Sink: HDFS (离线分析使用) ---
agent1.sinks.sink_hdfs.type = hdfs
agent1.sinks.sink_hdfs.hdfs.path = hdfs://localhost:9000/short-video/behavior/logs/%Y-%m-%d
# 如果没有HDFS，可以使用本地文件系统
# agent1.sinks.sink_hdfs.hdfs.path = file:///tmp/shortvideo/behavior/logs/%Y-%m-%d
agent1.sinks.sink_hdfs.hdfs.filePrefix = behavior_log_
agent1.sinks.sink_hdfs.hdfs.fileSuffix = .json
# 使用本地时间戳生成 %Y-%m-%d
agent1.sinks.sink_hdfs.hdfs.useLocalTimeStamp = true
# 滚动策略：10分钟 或 128MB 滚动一次
agent1.sinks.sink_hdfs.hdfs.rollInterval = 600
agent1.sinks.sink_hdfs.hdfs.rollSize = 134217728
agent1.sinks.sink_hdfs.hdfs.rollCount = 0
# 文件格式
agent1.sinks.sink_hdfs.hdfs.fileType = DataStream
agent1.sinks.sink_hdfs.hdfs.writeFormat = Text
agent1.sinks.sink_hdfs.hdfs.batchSize = 1000
agent1.sinks.sink_hdfs.hdfs.callTimeout = 60000
agent1.sinks.sink_hdfs.hdfs.idleTimeout = 60
# 不按时间轮转目录
agent1.sinks.sink_hdfs.hdfs.round = false
agent1.sinks.sink_hdfs.hdfs.roundValue = 0
agent1.sinks.sink_hdfs.hdfs.roundUnit = second
# 时区设置
agent1.sinks.sink_hdfs.hdfs.timeZone = Asia/Shanghai

# --- 连接关系 ---
agent1.sources.source_spooldir.channels = channel_offline
agent1.sinks.sink_hdfs.channel = channel_offline

# ====================================================================
# Agent2: 实时分析通道 - exec source监听generated_logs.json，输出到Kafka
# ====================================================================
agent2.sources = source_exec
agent2.sinks = sink_kafka
agent2.channels = channel_realtime

# --- Source: exec tail监听generated_logs.json（追加文件） ---
agent2.sources.source_exec.type = exec
# Windows环境使用PowerShell命令（需要根据实际情况调整路径）
# agent2.sources.source_exec.command = powershell -Command "Get-Content generated_logs.json -Wait -Tail 10"
# Linux/Mac环境使用tail命令
agent2.sources.source_exec.command = tail -F generated_logs.json
agent2.sources.source_exec.shell = /bin/sh -c
agent2.sources.source_exec.batchSize = 100
agent2.sources.source_exec.batchTimeout = 1000
# 自动重启
agent2.sources.source_exec.restart = true
agent2.sources.source_exec.restartThrottle = 10000
agent2.sources.source_exec.maxRestarts = 3

# --- Channel: 实时分析通道（内存类型，延迟低） ---
agent2.channels.channel_realtime.type = memory
agent2.channels.channel_realtime.capacity = 10000
agent2.channels.channel_realtime.transactionCapacity = 1000
# 可选：使用文件channel提高可靠性（如果对可靠性要求高）
# agent2.channels.channel_realtime.type = file
# agent2.channels.channel_realtime.checkpointDir = ./flume/checkpoint_realtime
# agent2.channels.channel_realtime.dataDirs = ./flume/data_realtime

# --- Sink: Kafka (实时分析使用) ---
agent2.sinks.sink_kafka.type = org.apache.flume.sink.kafka.KafkaSink
agent2.sinks.sink_kafka.kafka.bootstrap.servers = localhost:9092
agent2.sinks.sink_kafka.kafka.topic = shortvideo_user_behavior
agent2.sinks.sink_kafka.kafka.producer.acks = 1
agent2.sinks.sink_kafka.kafka.producer.linger.ms = 1
agent2.sinks.sink_kafka.kafka.producer.batch.size = 16384
agent2.sinks.sink_kafka.kafka.producer.compression.type = snappy

# --- 连接关系 ---
agent2.sources.source_exec.channels = channel_realtime
agent2.sinks.sink_kafka.channel = channel_realtime
